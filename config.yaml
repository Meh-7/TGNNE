# mvte/config.yaml

data:
  source: "pykeen"          # "files" or "pykeen"
  dataset: "FB15k-237"       # only used when source == "pykeen" : "FB15k-237", "WN18RR", "YAGO3-10", etc. 

  prepared_dir: "data/FB15k-237/"  # directory where prepared data is stored
  
  train_path: "data/train.txt"
  valid_path: "data/valid.txt"
  test_path: "data/test.txt"

model:
  base_scorer: "transe"    # "transe", "distmult", "complex", "rotate", etc.
  embedding_dim: 1000
  tri_hidden_dim: 128
  tet_hidden_dim: 128
  dropout: 0.1
  gamma: 12.0
  fusion_mode: "equal"   # "learned" | "topo_only" | "equal" | "custom"


topology:
  max_triangles_per_entity: null       # or null for no cap
  max_tetras_per_entity: null          # or null for no cap

training:
  seed: 314
  device: "cuda"                     # "auto", "cpu", "cuda", or "cuda:0"
  lr: 0.008
  num_epochs: 500
  batch_size: 1024
  num_negatives: 512
  adversarial_temperature: 1.0 # alpha for adv. neg. sampling
  negative_mode: "both"              # "head" | "tail" | "both"
  log_interval: 25
  checkpoint_every: 25                # save a checkpoint every N epochs


evaluation:
  batch_size_entities: 2048
  filtered: true  # whether to use filtered metrics, might be better to set it to false during training to monitor learning curves and true for final evaluation
  hits_ks: [1, 3, 10]
  eval_every: 25                      # run evaluation every N epochs
  max_eval_triples: 15000               # max number of triples to use for eval (for speed during training/validation)

testing:
  checkpoint_path: runs/FB15k-237/20251202_141522/mvte_model.pt

logging:
  level: "INFO"
  log_dir: "logs"

output:
  save_dir: "checkpoints"
